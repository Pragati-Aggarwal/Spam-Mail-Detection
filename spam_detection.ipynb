{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Emails.csv')\n",
    "data.head()\n",
    "\n",
    "data.drop(columns=['label'], inplace=True)\n",
    "data=data.iloc[:,1:]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabab4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']= data['text'].apply(lambda s:s.replace(\"Subject\",\"\"))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='label_num', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34206317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_msg = data[data.label_num == 0]\n",
    "spam_msg = data[data.label_num == 1]\n",
    "# print(spam_msg)\n",
    "\n",
    "ham_msg = ham_msg.sample(n=len(spam_msg), random_state=42)\n",
    "print(ham_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data= pd.concat((ham_msg,spam_msg)).reset_index(drop=True)\n",
    "plt.figure(figsize=(8,6))\n",
    "print(sns.countplot(data=balanced_data,x='label_num'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "print(punctuations_list)\n",
    "punctuations_list= punctuations_list+\"\\r\\n\"\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    temp = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(temp)\n",
    "\n",
    "balanced_data['text']= balanced_data['text'].apply(lambda x: remove_punctuations(x))\n",
    "print(balanced_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a19fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    imp_words = []\n",
    "\n",
    "    # Storing the important words\n",
    "    for word in str(text).split():\n",
    "        word = word.lower()\n",
    "\n",
    "        if word not in stop_words:\n",
    "            imp_words.append(word)\n",
    "\n",
    "    output = \" \".join(imp_words)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "balanced_data['text'] = balanced_data['text'].apply(lambda text: remove_stopwords(text))\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(data, typ):\n",
    "    email_corpus = \" \".join(data['text'])\n",
    "    wc = WordCloud(background_color='black', max_words=100, width=800, height=400).generate(email_corpus)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title(f'WordCloud for {typ} Emails', fontsize=15)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(balanced_data[balanced_data['label_num'] == 0], typ='Non-Spam')\n",
    "plot_word_cloud(balanced_data[balanced_data['label_num'] == 1], typ='Spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c672afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(balanced_data['text'], balanced_data['label_num'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_X)#generating train sequence\n",
    "test_sequences = tokenizer.texts_to_sequences(test_X)#generating test sequence\n",
    "\n",
    "#pad sequences to have the same length\n",
    "max_len = 100  # Maximum sequence length, it will be generated based on the sentence\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "print(train_sequences)#the no.s represent total frequency of every word in the data\n",
    "print(\"\\n\",test_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b5301d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32),\n",
    "    tf.keras.layers.LSTM(16),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04273c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=3, monitor='val_accuracy', restore_best_weights=True)\n",
    "lr = ReduceLROnPlateau(patience=2, monitor='val_loss', factor=0.5, verbose=0)\n",
    "\n",
    "history = model.fit(\n",
    "    train_sequences, train_Y,\n",
    "    validation_data=(test_sequences, test_Y),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr, es]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_sequences, test_Y)\n",
    "print('Test Loss :',test_loss)\n",
    "print('Test Accuracy :',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
